
%\subsection{Related work} 
The notions of wait-for-graph and supercycle \cite{AC05,AE98}
were initially defined for a shared memory program
$P = P_1 \pl \cdots \pl P_K$ in \emph{pairwise normal form} \cite{Att16a,Att16b}: a binary
symmetric relation $I$ specifies the directly interacting pairs
(``neighbors'') $\set{P_i, P_j}$ 
If $P_i$ has neighbors $P_j$ and $P_k$, then 
the code in $P_i$ that interacts with $P_j$ is expressed separately from
the code in $P_i$ that interacts with $P_k$. 
These synchronization codes are executed synchronously and
atomically, so the grain of atomicity is proportional to the
degree of $I$.
%
%Attie and Chockler \cite{AC05} give two polynomial time 
\citeN{AC05} give two polynomial time 
methods for (local and global) deadlock freedom.
The first checks subsystems consisting of three
processes. The second computes the wait-for-graphs of all pair subsystems $P_i \pl P_j$,
and takes their union, for all pairs
and all reachable states of each pair.
%Both methods consider in-paths and out-paths of length at most 2. The second
%method in addition considers the maximal strong components of $\mathcal{W}$. 
The first method considers only wait-for-paths of length $\le 2$. 
%due to the construction of $\mathcal{W}$, 
The second method is prone to false negatives,
%again due to $\mathcal{W}$, 
because wait-for edges generated by different states are
all merged together, which can result in spurious supercycles.


\citeN{GS03} use a BIP-like
%G{\"o}ssler and Sifakis \cite{GS03} use a BIP-like
formalism, Interaction Models. %, which uses multiparty interactions and
%connectors to specify synchronization between components. 
They present a criterion for global deadlock freedom, based on 
%a dependency graph, which is %(like our wait-for-graph)
an and-or graph with components and constraints as the two sets of nodes. A
constraint gives the condition
under which a component is blocked. Edges are labeled with conjuncts
of the constraints.  Deadlock freedom is checked by traversing every
cycle, taking the conjunction of all the
conditions labeling its edges, and verifying that this conjunction is
always false, \ie verifying the absence of cyclical blocking.
No complexity bounds are given.
%
%Martens and Majster-Cederbaum~\cite{MM12} present a polynomial time
\citeN{MM12} present a polynomial time
checkable deadlock freedom condition based on structural restrictions:
``the communication structure between the components is given by a
tree.'' This restriction allows them to analyze only pair systems.
%
%Aldini and Bernardo \cite{AB03} use a 
\citeN{AB03} use a 
formalism based on process algebra. They check deadlock by analyzing cycles in
the connections between software components, and claim scalability, but no
complexity bounds are given.

%Roscoe and Dathi \cite{RD87} present several rules for freedom of global deadlock of
\citeN{RD87} present several rules for freedom of global deadlock of
``triple disjoint'' (no action involves $> 2$ processes) CSP concurrent
programs. The basis for these rules is to first check that each individual process is deadlock free
(\ie the network is ``busy''), and then to define a ``variant function'' that maps the state of each
process to a partially ordered set. The first rule requires to establish that, if $P_i$ waits for
$P_j$, then the value of $P_i$'s state is greater than the value of $P_j$'s state. 
Since every process is blocked in a global deadlock, one can then construct an infinite sequence of
processes with strictly decreasing values, which are therefore all distinct. This cannot happen in a
finite network, and hence some process is not blocked.
They treat several examples, including
a self-timed systolic array (in 2 and 3 dimensions), dining philosophers, and a message switching
network.  They generalize the first rule to exploit ``disconnecting edges'' (whose removal
partitions the network into disconnected components) to decompose the proof of deadlock freedom into
showing that each disconnected component is deadlock-free, and also to weaken the restriction on the
variant function so that it only has to decrease for at least one edge on each wait-for cycle.
%
%Brookes and Roscoe~\cite{BR91} also provide criteria for deadlock
\citeN{BR91} also provide criteria for deadlock
freedom of triple-disjoint CSP programs, and use the same technical framework as
\citeN{RD87}.  However, they do not use variant functions, but show that, in a busy
network, a deadlock implies the existence of a wait-for cycle. They give many examples,
and demonstrate the absence of wait-for cycles in each example, by ad-hoc
reasoning. Finally, they give a deadlock freedom rule that exploits disconnecting edges,
similar to that of \citeN{RD87}.
%
In both of these papers, the wait-for relations are defined by examining a pair of processes
at a time: $P_i$ waits for $P_j$ iff $P_i$ offers an action to $P_j$ which $P_j$ is
not willing to participate in.

\citeN{Ma96} applies the results of \citeN{RD87} and \citeN{BR91} to formulate deadlock-freedom design rules for several classes of CSP concurrent
programs: cyclic processes, client-server protocols, and resource allocation protocols. He also introduces the notion of ``state dependence digraph''
(SDD), whose nodes are local states of individual processes, and whose edges are wait-for relations between processes in particular local states. An
acyclic SDD implies deadlock-freedom. A cyclic SDD does not imply deadlock, however, since the cycle may be ``spurious'': the local states along the
cycle may not be reachable at the same time, and so the cycle cannot give rise to an actual deadlock during execution. Hence the SDD approach cannot
deal with ``non-hereditary'' deadlock freedom, \ie a deadlock free system that contains a deadlock prone subsystem. Consider, \eg, the dining
philosophers with a butler solution; removing the butler leaves a deadlock prone subsystem.
%
%Antonio \etal \cite{AGR16} 
\citeN{AGR16} 
takes the SDD approach and improves its accuracy by checking for mutual reachability of pairs of local states, and also
eliminating local states and pairs of local states, where action enablement can be verified locally.
These checks are formulated as a Boolean formula which is then sent to
a SAT solver. Their method is able to verify deadlock freedom of
dining philosophers with a butler, whereas our method timed out, %our method for butler phils
since the subsystems on which $\LAO(B, Q_0, a, \l)$ is evaluated becomes the entire system.
On the other hand, our approach succeeded in quickly verifying deadlock-freedom of the resource
allocation example, whereas the method of 
%Antonio \etal \cite{AGR16} 
\citeN{AGR16} 
failed for Milner's token based scheduler, which is a special
case of our resource allocation example.
%
An intriguing topic for future work is to attempt to combine the two methods, to obtain the
advantages of both.



We compared our implementation \deadlocktool to D-Finder 2~\cite{DFinder2}. 
D-Finder 2 computes a finite-state abstraction for each component, which it uses
to compute a global invariant $I$. It then checks if $I$ 
implies deadlock freedom.  Unlike \deadlocktool, D-Finder 2 
handles infinite state systems.
However, \deadlocktool had superior running time for
dining philosophers and resource controller (both finite-state).

All the above methods (except \citeN{AC05}) verify global (and not
local) deadlock-freedom.  Our method verifies local deadlock-freedom, which subsumes 
global deadlock-freedom as a special case.
Also, our approach makes no
structural restriction at all on the system being checked for deadlock.  Our method checks
for the absence of supercycles, which are a sound and complete characterization of
deadlock. 
Moreover, the \LAO condition is complete \wrt the occurrence of a supercycle wholly
within the subsystem being checked, and the \GAO condition is complete
\wrt freedom from local and global deadlock, as given by
Theorem~\ref{theorem:gao-is-complete}.
None of the above papers give a completeness result similar to 
Theorem~\ref{theorem:gao-is-complete}.
%
Hence, the only source of incompleteness in our method is that of computational
limitation: if the subsystem being checked becomes too large before 
the \LAO condition is verified. If computational resources are not exhausted, then our
method can keep checking until the subsystem being checked is the entire system, at which
point \LAO coincides with \GAO, which is sound and complete for local deadlock
(\prop{scViol-iff-notInSC}, \defn{formation.violation}, and \defn{global.ANDOR-cond}).

\redbox{
The work of \citeN{Glabbeek2009} extends \CTLS with constructs to 
support expressing and distinguishing between deadlock, livelock, and successful
termination. 
%
This is key since the standard semantics of \CTLS requires that Kripke
structures be total, \ie every state has at least one outgoing
transition, and so deadlock cannot be modeled.
%
They provide a semantics for \CTLS in which deadlock, livelock, and successful
termination can all be distinguished.
% They then translate the extended formulae and the LTS systems they specify
% to Kripke structures where the total restriction is lifted. 
% %
% The work also suggests an alternative method to adapt the translation 
% from LTS systems into Kripke structures by adding a special $s_{\delta}$ state
% that has a self loop transition where this specific state characterizes deadlock. 
}

\redbox{
Abstraction methods related to compositional reasoning
\cite{AbdullaHH13VMCAI,PnueliRZ01TACAS,CohenN09FMSD}
that target safety properties can be used to prove
global deadlock freedom. 
%
The aforementioned papers %works in~\cite{AbdullaHH13VMCAI,PnueliRZ01TACAS,CohenN09FMSD}
target parametrized systems composed of $N$ communicating processes
$P_{i}, 1 \le i \le N$.
They over-approximate the reachable state space of a system with 
$N$ processes, using symbolic states from a system of size $K<N$.
If the property holds for the system of size $K$, then it holds for any arbitrary $N$.
%
Crucial to~\cite{AbdullaHH13VMCAI} is a bound on the number of processes
involved at each state, such that the post image (typically infinite) can be 
computed using successor operations of size $K+\ell$ where $\ell$ is a small 
constant. This limits the completeness of the technique to systems with specific
array, ring, and tree like topologies. 
%
\citeN{CohenN09FMSD} provides a global proof using 
several local proofs. 
It splits a target system invariant into local process invariants across 
local and shared variables and attempts to prove these invariants. 
The derived local invariants are symbolic over-approximations of the reachable 
state space of the system. 
The abstraction refinement step refines the invariants with predicates reasoning 
about additional local variables. 
}

\redbox{
\citeN{PnueliRZ01TACAS} targets a specific type of bounded data 
parametrized systems with parameter $N$, where $N$ is the number of
processes, and 
where safety is expressed using a specific type of assertions called $R$-assertions.
They show that for a given such system, there exists an $N_0$ such that, an
$R-$assertion $\phi$ is preserved by any step of the system for every $N>1$
iff  $\phi$ is preserved by any step of the system for every $N \le N_0$. 
They show how to handle such systems with model checking and deductive
reasoning techniques. 
% 
The survey paper~\cite{ClarkeKV10Memory} describes several abstraction 
techniques that use counterexamples to guide the refinement steps. 
It also describes a localization reduction technique~\cite{Kurshan94}.
%a dependency graph of the variables referenced in the safety property. 
The first abstraction is the property itself. 
%%In case, it passes model checking, then it  is a tautology. %????????????????????????????????????????????
If the model check fails, then an error ``track'' is produced, and either the track is feasible and the property
fails, or the track is analyzed and linked to 
a group of blocking variables that could not be assigned to satisfy the track. 
The blocking variables lead, via dependency graph paths, to active variables that have full 
assignments in the error track. 
All these variables constitute the next refinement step, where the border variables
are considered free and are called the ``free fence''. 
Key to the efficacy of the technique is the choice of the blocking variables,
so that they minimize the free fence at each abstraction step. 
Localization refinement is also used synergistically with input 
re-parameterization, to attain maximal input reduction in 
sequential netlists, using min-cut analysis 
in a structural manner~\cite{BaumgartnerM05Charme}. 
The reduced netlists are then subject to verification using several 
techniques, including decomposing the netlist into several sub-netlists, each 
with a bounded state transition diameter, and then applying bounded model checking
~\cite{BaumgartnerK04Date,BaumgartnerKA02CAV} to each sub-netlist. 
%
Our work differs from the above techniques in that 
(1) we do not limit our technique to 
parametrized systems, 
(2) we characterize deadlock freedom with a structural supercycle property
that governs the wait-for-graph of the system interactions, 
(3) we compute our local subsystems based on interactions, 
(4) we establish deadlock freedom by performing the structural supercycle violation
check for each interaction using its local subsystems,  and
(5) our technique is complete for BIP systems. 
In the future, we would like to explore whether the local supercycle violation check
is enough to prove deadlock-freedom of parametrized systems. 
We would also like to consider characterizing other interesting safety properties with
similar structural checks in the context of BIP. 
}


%\cite{AbdullaHH13VMCAI}
%\cite{PnueliRZ01TACAS}
%\cite{CohenN09FMSD}
%\cite{ClarkeKV10Memory}



\subsection{Discussion}
Our approach has the following advantages:
\begin{itemize}

\item \emph{Local and global deadlock}: our method shows that no subset of processes
  can be deadlocked, \ie absence of both local and global deadlock. 

\item \emph{Check works for realistic formalism}:  by applying the approach to BIP, we
provide an efficient deadlock-freedom check within a formalism from
which efficient distributed implementations can be generated
\cite{BonakdarpourBJQS10b}.  

\item \emph{Locality}: if a component $B_i$ is modified, or is added to an
  existing system, then $\LAO(B, Q_0, a, \l)$ only has to
  be re-checked for $B_i$ and components within distance $\l$ of $B_i$.
  A condition whose evaluation considers the entire
  system at once, \eg \cite{AB03,DFinder2,GS03}
  would have to be re-checked for the entire system. 

\item \emph{Easily parallelizable}: since the checking of each subsystem $\dsk{a}{\l}$
  is independent of the others, the checks can be carried out in parallel. Hence
  our method can be easily parallelized and distributed, for speedup, if needed.
  Alternatively, performing the checks sequentially
  minimizes the amount of memory needed. 

\item \emph{Framework aspect}: supercycles and in/out-depth provide a \emph{framework} for
  deadlock-freedom. Conditions more general and/or discriminating than
  the one presented here 
  should be devisable in this framework. This is a topic for future work.
In addition, our approach is applicable to any model of concurrency in
which our notions of wait-for graph and supercycle can be defined. For example,  
%Attie and Chockler \cite{AC05} 
\citeN{AC05} 
give two methods for verifying global
and local deadlock freedom of shared-memory concurrent programs in pairwise normal form, as noted above.
Hence, our methods are applicable to other formalisms such as CSP, CCS, I/O Automata, etc.


\end{itemize}


\subsection{Further work} 
Our implementation uses explicit state enumeration. % to evaluate $\LDFC(a, \l)$.
Using BDD's may improve the running time 
when $\LAO(B, Q_0, a, \l)$ holds only for large $\l$.
Another potential method for improving the running time is to use 
SAT solving, cf.\ \citeN{AGR16}.
%
%, since the time to check $\LDFC(a, \l)$ grows exponentially with $\l$, in general.
%
An enabled port $p$ enables all interactions containing $p$.
Deadlock-freedom conditions based on ports could exploit
this interdependence among interaction enablement.
%
Our implementation should produce \emph{counterexamples} when a system fails to satisfy $\LAO(B, Q_0, a, \l)$. These can be used to manually modify the system
to eliminate a possible deadlock.  Also, when $\LAO(B, Q_0, a, \l)$ fails to verify deadlock-freedom, we increment $\l$, in effect extending the
subsystem being checked ``in all directions'' away from $a$ (in the structure graph). A counterexample may provide guidance to a more discriminating
extension, when adds only a few components, so we now consider subsystems whose boundary has varying distance from $a$, in the structure graph. This
has the benefit that we might verify deadlock freedom using a smaller subsystem than with our current approach.
%
\emph{Design rules} for ensuring $\LAO(B, Q_0, a, \l)$ will help users to
produce deadlock-free systems, and also to interpret counterexamples.
%
A \emph{fault} may create a deadlock,  \ie a supercycle, by creating 
wait-for-edges that would not normally arise.
Tolerating a fault that creates up to $f$ such spurious wait-for-edges 
requires that there do not arise during normal
(fault-free) operation subgraphs of $\wfg{B}{s}$ that can be made into a
supercycle by adding $f$ edges. 
We will investigate criteria for preventing formation of such subgraphs.
%
Methods for evaluating $\LAO(B, Q_0, a, \l)$ on \emph{infinite state} systems will be
devised, \eg, by extracting proof obligations and verifying using SMT solvers.
%This verifies local deadlock freedom, which, unlike global deadlock freedom,
%cannot be succinctly expressed in first order logic.
%
We will extend our method to \emph{Dynamic BIP},
\cite{DBLP:conf/soco/BozgaJMS12}, where participants can add and remove
interactions at run time.


