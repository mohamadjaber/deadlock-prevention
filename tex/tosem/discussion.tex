
\subsection{Related work.} 
The notions of wait-for-graph and supercycle \cite{AC05,AE98}
were initially defined for a shared memory program
$P = P_1 \pl \cdots \pl P_K$ in \emph{pairwise normal form} \cite{Att16a,Att16b}: a binary
symmetric relation $I$ specifies the directly interacting pairs
(``neighbors'') $\set{P_i, P_j}$ 
If $P_i$ has neighbors $P_j$ and $P_k$, then 
the code in $P_i$ that interacts with $P_j$ is expressed separately from
the code in $P_i$ that interacts with $P_k$. 
These synchronization codes are executed synchronously and
atomically, so the grain of atomicity is proportional to the
degree of $I$.
%
%Attie and Chockler \cite{AC05} give two polynomial time 
\citeN{AC05} give two polynomial time 
methods for (local and global) deadlock freedom.
The first checks subsystems consisting of three
processes. The second computes the wait-for-graphs of all pair subsystems $P_i \pl P_j$,
and takes their union, for all pairs
and all reachable states of each pair.
%Both methods consider in-paths and out-paths of length at most 2. The second
%method in addition considers the maximal strong components of $\mathcal{W}$. 
The first method considers only wait-for-paths of length $\le 2$. 
%due to the construction of $\mathcal{W}$, 
The second method is prone to false negatives,
%again due to $\mathcal{W}$, 
because wait-for edges generated by different states are
all merged together, which can result in spurious supercycles.


\citeN{GS03} use a BIP-like
%G{\"o}ssler and Sifakis \cite{GS03} use a BIP-like
formalism, Interaction Models. %, which uses multiparty interactions and
%connectors to specify synchronization between components. 
They present a criterion for global deadlock freedom, based on 
%a dependency graph, which is %(like our wait-for-graph)
an and-or graph with components and constraints as the two sets of nodes. A
constraint gives the condition
under which a component is blocked. Edges are labeled with conjuncts
of the constraints.  Deadlock freedom is checked by traversing every
cycle, taking the conjunction of all the
conditions labeling its edges, and verifying that this conjunction is
always false, \ie verifying the absence of cyclical blocking.
No complexity bounds are given.
%
%Martens and Majster-Cederbaum~\cite{MM12} present a polynomial time
\citeN{MM12} present a polynomial time
checkable deadlock freedom condition based on structural restrictions:
``the communication structure between the components is given by a
tree.'' This restriction allows them to analyze only pair systems.
%
%Aldini and Bernardo \cite{AB03} use a 
\citeN{AB03} use a 
formalism based on process algebra. They check deadlock by analyzing cycles in
the connections between software components, and claim scalability, but no
complexity bounds are given.

%Roscoe and Dathi \cite{RD87} present several rules for freedom of global deadlock of
\citeN{RD87} present several rules for freedom of global deadlock of
``triple disjoint'' (no action involves $> 2$ processes) CSP concurrent
programs. The basis for these rules is to first check that each individual process is deadlock free
(\ie the network is ``busy''), and then to define a ``variant function'' that maps the state of each
process to a partially ordered set. The first rule requires to establish that, if $P_i$ waits for
$P_j$, then the value of $P_i$'s state is greater than the value of $P_j$'s state. 
Since every process is blocked in a global deadlock, one can then construct an infinite sequence of
processes with strictly decreasing values, which are therefore all distinct. This cannot happen in a
finite network, and hence some process is not blocked.
They treat several examples, including
a self-timed systolic array (in 2 and 3 dimensions), dining philosophers, and a message switching
network.  They generalize the first rule to exploit ``disconnecting edges'' (whose removal
partitions the network into disconnected components) to decompose the proof of deadlock freedom into
showing that each disconnected component is deadlock-free, and also to weaken the restriction on the
variant function so that it only has to decrease for at least one edge on each wait-for cycle.
%
%Brookes and Roscoe~\cite{BR91} also provide criteria for deadlock
\citeN{BR91} also provide criteria for deadlock
freedom of triple-disjoint CSP programs, and use the same technical framework as
\citeN{RD87}.  However, they do not use variant functions, but show that, in a busy
network, a deadlock implies the existence of a wait-for cycle. They give many examples,
and demonstrate the absence of wait-for cycles in each example, by ad-hoc
reasoning. Finally, they give a deadlock freedom rule that exploits disconnecting edges,
similar to that of \citeN{RD87}.
%
In both of these papers, the wait-for relations are defined by examining a pair of processes
at a time: $P_i$ waits for $P_j$ iff $P_i$ offers an action to $P_j$ which $P_j$ is
not willing to participate in.

\citeN{Ma96} applies the results of \citeN{RD87} and \citeN{BR91} to formulate deadlock-freedom design rules for several classes of CSP concurrent
programs: cyclic processes, client-server protocols, and resource allocation protocols. He also introduces the notion of ``state dependence digraph''
(SDD), whose nodes are local states of individual processes, and whose edges are wait-for relations between processes in particular local states. An
acyclic SDD implies deadlock-freedom. A cyclic SDD does not imply deadlock, however, since the cycle may be ``spurious'': the local states along the
cycle may not be reachable at the same time, and so the cycle cannot give rise to an actual deadlock during execution. Hence the SDD approach cannot
deal with ``non-hereditary'' deadlock freedom, \ie a deadlock free system that contains a deadlock prone subsystem. Consider, \eg, the dining
philosophers with a butler solution; removing the butler leaves a deadlock prone subsystem.
%
%Antonio \etal \cite{AGR16} 
\citeN{AGR16} 
takes the SDD approach and improves its accuracy by checking for mutual reachability of pairs of local states, and also
eliminating local states and pairs of local states, where action enablement can be verified locally.
These checks are formulated as a Boolean formula which is then sent to
a SAT solver. Their method is able to verify deadlock freedom of
dining philosophers with a butler, whereas our method timed out, %our method for butler phils
since the subsystems on which $\LAO(B, Q_0, a, \l)$ is evaluated becomes the entire system.
On the other hand, our approach succeeded in quickly verifying deadlock-freedom of the resource
allocation example, whereas the method of 
%Antonio \etal \cite{AGR16} 
\citeN{AGR16} 
failed for Milner's token based scheduler, which is a special
case of our resource allocation example.
%
An intriguing topic for future work is to attempt to combine the two methods, to obtain the
advantages of both.



We compared our implementation \deadlocktool to D-Finder 2~\cite{DFinder2}. D-Finder 2
computes a finite-state abstraction for each component, which it uses
to compute a global invariant $I$. It then checks if $I$ 
implies deadlock freedom.  Unlike \deadlocktool, D-Finder 2 
handles infinite state systems.
However, \deadlocktool had superior running time for
dining philosophers and resource controller (both finite-state).


All the above methods (except \citeN{AC05}) verify global (and not
local) deadlock-freedom.  Our method verifies local deadlock-freedom, which subsumes 
global deadlock-freedom as a special case.
Also, our approach makes no
structural restriction at all on the system being checked for deadlock.  Our method checks
for the absence of supercycles, which are a sound and complete characterization of
deadlock, and the \LAO condition is complete \wrt the occurrence of a supercycle wholly
within the subsystem being checked. 
Hence the only source of incompleteness in our method is that of computational
limitation: if the subsystem being checked becomes too large before 
the \LAO condition is verified. If computational resources are not exhausted, then our
method can keep checking until the subsystem being checked is the entire system, at which
point \LAO coincides with \GAO, which is sound and complete for local deadlock
(\prop{scViol-iff-notInSC}, \defn{formation.violation}, and \defn{global.ANDOR-cond}).






\subsection{Discussion}
Our approach has the following advantages:
\begin{description}

\item[Local and global deadlock] Our method shows that no subset of processes
  can be deadlocked, \ie absence of both local and global deadlock. 

\item[Check works for realistic formalism]   By applying the approach to BIP, we
provide an efficient deadlock-freedom check within a formalism from
which efficient distributed implementations can be generated
\cite{BonakdarpourBJQS10b}.  

\item[Locality] If a component $B_i$ is modified, or is added to an
  existing system, then $\LAO(B, Q_0, a, \l)$ only has to
  be re-checked for $B_i$ and components within distance $\l$ of $B_i$.
  A condition whose evaluation considers the entire
  system at once, \eg \cite{AB03,DFinder2,GS03}
  would have to be re-checked for the entire system. 

\item[Easily parallelizable] Since the checking of each subsystem $\dsk{a}{\l}$
  is independent of the others, the checks can be carried out in parallel. Hence
  our method can be easily parallelized and distributed, for speedup, if needed.
  Alternatively, performing the checks sequentially
  minimizes the amount of memory needed. 

\item[Framework aspect] Supercycles and in/out-depth provide a \emph{framework} for
  deadlock-freedom. Conditions more general and/or discriminating than
  the one presented here 
  should be devisable in this framework. This is a topic for future work.
In addition, our approach is applicable to any model of concurrency in
which our notions of wait-for graph and supercycle can be defined. For example,  
%Attie and Chockler \cite{AC05} 
\citeN{AC05} 
give two methods for verifying global
and local deadlock freedom of shared-memory concurrent programs in pairwise normal form, as noted above.
Hence, our methods are applicable to other formalisms such as CSP, CCS, I/O Automata, etc.


\end{description}


\subsection{Further work.} 
Our implementation uses explicit state enumeration. % to evaluate $\LDFC(a, \l)$.
Using BDD's may improve the running time 
when $\LAO(B, Q_0, a, \l)$ holds only for large $\l$.
Another potential method for improving the running time is to use 
SAT solving, cf.\ \citeN{AGR16}.
%
%, since the time to check $\LDFC(a, \l)$ grows exponentially with $\l$, in general.
%
An enabled port $p$ enables all interactions containing $p$.
Deadlock-freedom conditions based on ports could exploit
this interdependence among interaction enablement.
%
Our implementation should produce \emph{counterexamples} when a system fails to satisfy $\LAO(B, Q_0, a, \l)$. These can be used to manually modify the system
to eliminate a possible deadlock.  Also, when $\LAO(B, Q_0, a, \l)$ fails to verify deadlock-freedom, we increment $\l$, in effect extending the
subsystem being checked ``in all directions'' away from $a$ (in the structure graph). A counterexample may provide guidance to a more discriminating
extension, when adds only a few components, so we now consider subsystems whose boundary has varying distance from $a$, in the structure graph. This
has the benefit that we might verify deadlock freedom using a smaller subsystem than with our current approach.
%
\emph{Design rules} for ensuring $\LAO(B, Q_0, a, \l)$ will help users to
produce deadlock-free systems, and also to interpret counterexamples.
%
A \emph{fault} may create a deadlock,  \ie a supercycle, by creating 
wait-for-edges that would not normally arise.
Tolerating a fault that creates up to $f$ such spurious wait-for-edges 
requires that there do not arise during normal
(fault-free) operation subgraphs of $\wfg{B}{s}$ that can be made into a
supercycle by adding $f$ edges. 
We will investigate criteria for preventing formation of such subgraphs.
%
Methods for evaluating $\LAO(B, Q_0, a, \l)$ on \emph{infinite state} systems will be
devised, \eg, by extracting proof obligations and verifying using SMT solvers.
%This verifies local deadlock freedom, which, unlike global deadlock freedom,
%cannot be succinctly expressed in first order logic.
%
We will extend our method to \emph{Dynamic BIP},
\cite{DBLP:conf/soco/BozgaJMS12}, where participants can add and remove
interactions at run time.


